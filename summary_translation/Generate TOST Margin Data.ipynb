{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8dcd3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:57:21.603462Z",
     "start_time": "2022-04-26T19:57:18.573892Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "from utils import read_data_into_dataframe, qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddf1f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:57:21.754212Z",
     "start_time": "2022-04-26T19:57:21.609301Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/scores_human_from_SummEval.json\") as f:\n",
    "    scores_human = json.load(f)\n",
    "\n",
    "translations_summaries = []\n",
    "with open(\"data/translations_summaries.jsonl\") as f:\n",
    "    for line in f:\n",
    "        translations_summaries.append(json.loads(line))\n",
    "        \n",
    "translations_texts_refs = []\n",
    "with open(\"data/translations_texts_refs.jsonl\") as f:\n",
    "    for line in f:\n",
    "        translations_texts_refs.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b93a3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:57:21.764693Z",
     "start_time": "2022-04-26T19:57:21.756001Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_samples(translations_summaries, translations_texts_refs, scores_human):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        samples: List of 1700 samples, each sample is a dictionary. \n",
    "            It has id, the text and the summary, the rererence summaries, \n",
    "            and 4 human scores (from 3 experts from SummEval) - for the four qualities of the summary.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    for i, translations_summary in enumerate(translations_summaries):\n",
    "        summary = translations_summary['texts'][0]\n",
    "        i_text = i // 17\n",
    "        i_ref = i % 17\n",
    "        if i_ref == 0:\n",
    "            translations_text_refs = translations_texts_refs[i_text]\n",
    "            id_text = translations_text_refs['id']\n",
    "            text = translations_text_refs['texts'][0]\n",
    "            references = translations_text_refs['texts'][1:]\n",
    "        sample = {\n",
    "            'id': id_text,\n",
    "            'decoded': summary,\n",
    "            'references': references,\n",
    "            'text': text,\n",
    "            'expert_annotations': [\n",
    "                expert_annotations(scores_human, i, 0),\n",
    "                expert_annotations(scores_human, i, 1),\n",
    "                expert_annotations(scores_human, i, 2)\n",
    "            ]\n",
    "        }\n",
    "        samples.append(sample)\n",
    "    return samples\n",
    "\n",
    "\n",
    "def expert_annotations(scores_human, id_sample, id_expert):\n",
    "    scores = {\n",
    "        'coherence': scores_human[0][id_expert][id_sample],\n",
    "        'consistency': scores_human[1][id_expert][id_sample],\n",
    "        'fluency': scores_human[2][id_expert][id_sample],\n",
    "        'relevance': scores_human[3][id_expert][id_sample]\n",
    "    }\n",
    "    return scores\n",
    "\n",
    "\n",
    "def create_nested(df, primary, secondary, values):\n",
    "\n",
    "    return {k: f.set_index(secondary)[values].to_dict() for k, f in df.groupby(primary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dce8a46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:57:21.778755Z",
     "start_time": "2022-04-26T19:57:21.766965Z"
    }
   },
   "outputs": [],
   "source": [
    "expert = get_samples(translations_summaries, translations_texts_refs, scores_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733c4c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:57:21.784384Z",
     "start_time": "2022-04-26T19:57:21.781173Z"
    }
   },
   "outputs": [],
   "source": [
    "measures = [\n",
    "    \"bertscores_F\",\n",
    "    \"rougeL\",\n",
    "    \"rouge1\",\n",
    "    \"rouge2\",\n",
    "    \"bleu\",\n",
    "    \"jshannon\",\n",
    "    \"blanc\",\n",
    "    \"estime\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14a8da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:57:27.656589Z",
     "start_time": "2022-04-26T19:57:21.786703Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, sample in enumerate(expert):\n",
    "    for idx, evaluator in enumerate(sample[\"expert_annotations\"]):\n",
    "        data.append(\n",
    "            [\n",
    "                i,\n",
    "                idx,\n",
    "                evaluator[\"coherence\"],\n",
    "                evaluator[\"consistency\"],\n",
    "                evaluator[\"fluency\"],\n",
    "                evaluator[\"relevance\"],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = [\n",
    "    \"sample_id\",\n",
    "    \"expert_id\",\n",
    "    \"coherence\",\n",
    "    \"consistency\",\n",
    "    \"fluency\",\n",
    "    \"relevance\",\n",
    "]\n",
    "\n",
    "scores = read_data_into_dataframe()\n",
    "english = scores.loc[scores.language == \"en\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a30ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:57:28.353751Z",
     "start_time": "2022-04-26T19:57:27.658640Z"
    }
   },
   "outputs": [],
   "source": [
    "correlations = []\n",
    "for ex_id in range(3):\n",
    "    for metric in english.submetric.drop_duplicates().tolist():\n",
    "        for quality in qualities:\n",
    "            if metric in qualities:\n",
    "                continue\n",
    "            if metric not in measures:\n",
    "                continue\n",
    "\n",
    "            met_df = english.loc[english.submetric == metric]\n",
    "            exp = df.loc[(df.expert_id == ex_id), ['sample_id', quality]].set_index('sample_id')\n",
    "            \n",
    "            merged = met_df.merge(exp, left_on='data_idx', right_index=True)\n",
    "            correlation = kendalltau(merged.value, merged[quality]).correlation\n",
    "            \n",
    "            correlations.append(dict(\n",
    "                metric=metric,\n",
    "                quality=quality,\n",
    "                expert_id=ex_id,\n",
    "                correlation=correlation\n",
    "            ))\n",
    "            \n",
    "            \n",
    "margin = pd.DataFrame(correlations)\n",
    "merged_stats = (\n",
    "    margin\n",
    "    .groupby([\"metric\", \"quality\"])[\"correlation\"]\n",
    "    .agg([\"mean\", np.std])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "margin_max_min = (\n",
    "    margin.groupby([\"metric\", \"quality\"])[\"correlation\"]\n",
    "    .agg([\"max\", \"min\"])\n",
    "    .reset_index()\n",
    "    .assign(difference=lambda x: x[\"max\"] - x[\"min\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd408d23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:57:28.386228Z",
     "start_time": "2022-04-26T19:57:28.357339Z"
    }
   },
   "outputs": [],
   "source": [
    "diff_dict = margin_max_min.set_index([\"metric\", \"quality\"]).difference.to_dict()\n",
    "stat_dict = merged_stats.set_index([\"metric\", \"quality\"])[\"std\"].to_dict()\n",
    "\n",
    "with open(\"data/margins.json\", \"w\") as f:\n",
    "    json.dump(\n",
    "        dict(\n",
    "            max_margin=create_nested(margin_max_min, \"metric\", \"quality\", \"difference\"),\n",
    "            std=create_nested(merged_stats, \"metric\", \"quality\", \"std\"),\n",
    "        ),\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5b0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
