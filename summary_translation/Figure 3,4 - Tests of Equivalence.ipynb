{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096bc96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.033378Z",
     "start_time": "2022-04-26T19:49:19.803993Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, kendalltau\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import read_data_into_dataframe, qualities\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca1fae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.037851Z",
     "start_time": "2022-04-26T19:49:22.037835Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = read_data_into_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf79636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.039264Z",
     "start_time": "2022-04-26T19:49:22.039243Z"
    }
   },
   "outputs": [],
   "source": [
    "auto_measures = [\n",
    "    \"bertscores_F\",\n",
    "    \"rougeL\",\n",
    "    \"rouge1\",\n",
    "    \"rouge2\",\n",
    "    \"bleu\",\n",
    "    \"jshannon\",\n",
    "    \"blanc\",\n",
    "    \"estime\",\n",
    "]\n",
    "\n",
    "renamer = {\n",
    "    'bertscores_F': 'BERTScore',\n",
    "    'rougeL': \"ROUGE-L\",\n",
    "    'rouge1': \"ROUGE-1\",\n",
    "    'rouge2': \"ROUGE-2\",\n",
    "    'bleu': \"BLEU\",\n",
    "    'jshannon':\"JS\",\n",
    "    'blanc':\"BLANC\",\n",
    "    'estime': 'ESTIME'\n",
    "}\n",
    "figure1_columns = [\"Metric\", \"EN-DE\", \"EN-FR\", \"EN-ES\", \"EN-IT\", \"EN-AF\", \"EN-HI\", \"EN-RU\"]\n",
    "\n",
    "negative_corrs = [\"jshannon\", \"estime\"]\n",
    "non_en = all_data.loc[all_data.language != \"en\", \"language\"].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d83731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.040559Z",
     "start_time": "2022-04-26T19:49:22.040542Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_true_correlations(all_scores):\n",
    "    # transform [experts, en, es, fr, ...] -> [experts, language, value]\n",
    "    long_data = pd.melt(all_scores, id_vars=\"experts\", var_name=\"language\", value_name=\"value\")\n",
    "\n",
    "    # calc correlations between experts and each language\n",
    "    corrs = long_data.groupby(\"language\").apply(\n",
    "        lambda x: kendalltau(x.experts, x['value'], \"c\").correlation\n",
    "    )\n",
    "    \n",
    "    # calc correlation differences between english and non eng languages\n",
    "    # return df of form [language, difference]\n",
    "    return (\n",
    "        corrs\n",
    "        .reset_index(name='true')\n",
    "        .assign(single_index=1)\n",
    "        .pivot(index=\"single_index\", columns=\"language\")[\"true\"]\n",
    "        .melt(id_vars=[\"en\"])\n",
    "        .assign(true_difference=lambda x: x.en - x.value)\n",
    "        .loc[:,['language', 'true_difference']]\n",
    "    )\n",
    "\n",
    "\n",
    "def run_bootstrap(all_scores, n_samples=1000):\n",
    "    \n",
    "    # create df of sampled indexes for each bootstrap sample\n",
    "    bootidxs = {idx: np.random.randint(1700, size=1700) for idx in range(n_samples)}\n",
    "    idx_frame = pd.melt(pd.DataFrame(bootidxs), var_name='sample_no', value_name='idx')\n",
    "    \n",
    "    # create bootstrap samples by merging with data\n",
    "    boot_samples = idx_frame.merge(all_scores, left_on=\"idx\", right_index=True).sort_values(\n",
    "        [\"sample_no\", \"idx\"]\n",
    "    )\n",
    "    \n",
    "    # pivot from wide [sample, idx, experts, en, fr, ...] \n",
    "    # to long [sample, idx, experts, language, value]\n",
    "    boot_tidy = pd.melt(\n",
    "        boot_samples,\n",
    "        id_vars=[\"sample_no\", \"idx\", \"experts\"],\n",
    "        value_name=\"value\",\n",
    "        var_name=\"language\",\n",
    "    )\n",
    "    \n",
    "    # calc correlation differences btwn en and other langs using each bootstrap sample\n",
    "    correlations = (\n",
    "        boot_tidy\n",
    "        .groupby([\"sample_no\", \"language\"])\n",
    "        .apply(lambda x: kendalltau(x[\"experts\"], x[\"value\"], \"c\").correlation)\n",
    "        .reset_index(name=\"correlation\")\n",
    "        .pivot(index='sample_no', columns='language')['correlation']\n",
    "        .melt(id_vars=['en'])\n",
    "        .assign(difference = lambda x: x['en'] - x['value'])\n",
    "    )\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "\n",
    "def bootstrap_correlation_scores(df, quality_names, metrics, n_samples = 10000, seed=123):\n",
    "    np.random.seed(seed)\n",
    "    corr_dfs = []\n",
    "    for qual in tqdm(quality_names):\n",
    "        for met in tqdm(metrics):\n",
    "\n",
    "            expert = df.loc[\n",
    "                (df.submetric == qual)\n",
    "                & (df.metric == \"experts\")\n",
    "                & (df.language == \"en\"),\n",
    "                \"value\",\n",
    "            ].reset_index(drop=True)\n",
    "\n",
    "            english = df.loc[\n",
    "                (df.submetric == met) & (df.language == \"en\"), \"value\"\n",
    "            ].reset_index(drop=True)\n",
    "\n",
    "            df_list = [expert, english]\n",
    "\n",
    "            for lang in non_en:\n",
    "                df_list.append(df.loc[\n",
    "                    (df.submetric == met) & (df.language == lang), \"value\"\n",
    "                ].reset_index(drop=True))\n",
    "\n",
    "\n",
    "            all_scores = pd.concat(df_list, axis=1)\n",
    "            all_scores.columns = [\"experts\", \"en\"] + non_en\n",
    "\n",
    "            correlations = run_bootstrap(all_scores, n_samples=n_samples)\n",
    "            true_corrs = calc_true_correlations(all_scores)\n",
    "\n",
    "            correlations['metric'] = met\n",
    "            correlations['quality'] = qual\n",
    "            corr_dfs.append(correlations.merge(true_corrs, on='language'))\n",
    "\n",
    "    corr = pd.concat(corr_dfs)\n",
    "    return corr\n",
    "\n",
    "\n",
    "def tost_test(corr, margin=0.1):\n",
    "    corr = deepcopy(corr)\n",
    "    \n",
    "    if isinstance(margin, float):    \n",
    "        corr['higher_hypothesis'] = (corr['difference'] > margin)\n",
    "        corr['lower_hypothesis'] = (corr['difference'] < -margin)\n",
    "    else:\n",
    "        corr['higher_hypothesis'] = (corr['difference'] > corr[f'margin_{margin}'])\n",
    "        corr['lower_hypothesis'] = (corr['difference'] < -corr[f'margin_{margin}'])\n",
    "    \n",
    "    tost = (\n",
    "        corr.groupby([\"metric\", \"language\", \"quality\"])[\n",
    "            [\"higher_hypothesis\", \"lower_hypothesis\"]\n",
    "        ]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    tost[\"pvalue\"] = tost.apply(\n",
    "        lambda x: max(x[\"higher_hypothesis\"], x[\"lower_hypothesis\"]), axis=1\n",
    "    )\n",
    "\n",
    "    return tost\n",
    "\n",
    "\n",
    "def tost_corrected(tost_df, margin_name):\n",
    "    reject, corrected, _, _ = multipletests(\n",
    "        tost_df.pvalue,\n",
    "        alpha=0.05,\n",
    "        method=\"fdr_by\",\n",
    "        is_sorted=False,\n",
    "        returnsorted=False,\n",
    "    )\n",
    "    print(\n",
    "        f\"Pre Correction Rejection % {tost_df.pvalue.apply(lambda x: x <= 0.05).mean()*100:.2f}\"\n",
    "    )\n",
    "    print(f\"BY Correction Rejection % {reject.mean()*100:.2f}\")\n",
    "    tost_df[\"reject_by\"] = reject\n",
    "    tost_df[\"pval_by\"] = corrected\n",
    "\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    tost_df.pvalue.hist(alpha=0.3, label=\"Before Correction\")\n",
    "    tost_df.pval_by.hist(alpha=0.3, label=\" B-Y Corrected\")\n",
    "\n",
    "    plt.xticks(size=14)\n",
    "    plt.yticks(size=14)\n",
    "    plt.xlabel(\"p-value\", size=14)\n",
    "    plt.ylabel(\"Count\", size=14)\n",
    "    plt.title(f\"{margin_name} Margin\", size=15)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b575ef75",
   "metadata": {},
   "source": [
    "Warning - bootstrap may take some time to run. Set `new_run=True` to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f823d63e",
   "metadata": {},
   "source": [
    "## Run Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e242a76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.041664Z",
     "start_time": "2022-04-26T19:49:22.041648Z"
    }
   },
   "outputs": [],
   "source": [
    "new_run = False\n",
    "n_samples = 10000\n",
    "if new_run:\n",
    "    corr = run_bootstrap(all_data, n_samples)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    corr.to_csv(f\"bootstrap_forwardtranslation_{n_samples}iters_{timestamp}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0d3a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.042885Z",
     "start_time": "2022-04-26T19:49:22.042870Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"data/margins.json\") as f:\n",
    "    margins = json.load(f)\n",
    "\n",
    "corr['margin_std'] = corr.apply(lambda x: margins['std'][x.metric][x.quality], axis=1)\n",
    "corr['margin_maxdiff'] = corr.apply(lambda x: margins['max_margin'][x.metric][x.quality], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21731693",
   "metadata": {},
   "source": [
    "## Calculate TOST results for Difference Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d477d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.044111Z",
     "start_time": "2022-04-26T19:49:22.044096Z"
    }
   },
   "outputs": [],
   "source": [
    "tost_maxdiff = tost_test(corr, margin='maxdiff')\n",
    "tost_corrected(tost_maxdiff, 'Max Difference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24d3f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.045534Z",
     "start_time": "2022-04-26T19:49:22.045519Z"
    }
   },
   "outputs": [],
   "source": [
    "tost_std = tost_test(corr, margin='std')\n",
    "tost_corrected(tost_std, 'Standard Deviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959389a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.046793Z",
     "start_time": "2022-04-26T19:49:22.046778Z"
    }
   },
   "outputs": [],
   "source": [
    "tost_constant = tost_test(corr, margin=0.05)\n",
    "tost_corrected(tost_constant, 'Constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6875cef",
   "metadata": {},
   "source": [
    "## Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7acec1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.048010Z",
     "start_time": "2022-04-26T19:49:22.047990Z"
    }
   },
   "outputs": [],
   "source": [
    "trace = []\n",
    "\n",
    "for margin in np.linspace(0.001, 0.25, 100):\n",
    "    tost = tost_test(corr, margin=margin)\n",
    "\n",
    "    trace.append(\n",
    "        tost\n",
    "        .groupby(['quality'])\n",
    "        ['pvalue']\n",
    "        .agg([('total', 'count'), ('reject', lambda x: (x<=0.05).sum())])\n",
    "        .reset_index()\n",
    "        .assign(margin=margin)\n",
    "        .assign(pct=lambda x: 1.0 * x[\"reject\"] / x['total'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2f726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.050337Z",
     "start_time": "2022-04-26T19:49:22.050315Z"
    }
   },
   "outputs": [],
   "source": [
    "remap = defaultdict(list)\n",
    "for mtype, sub in margins.items():\n",
    "    for metric, qualdict in sub.items():\n",
    "        if metric in auto_measures:\n",
    "            for qual, val in qualdict.items():\n",
    "                remap['margin'].append(mtype)\n",
    "                remap['metric'].append(metric)\n",
    "                remap['quality'].append(qual)\n",
    "                remap['value'].append(val)\n",
    "                \n",
    "margin_df = pd.DataFrame(remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0ed74a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.052264Z",
     "start_time": "2022-04-26T19:49:22.052245Z"
    }
   },
   "outputs": [],
   "source": [
    "margin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e5ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.053819Z",
     "start_time": "2022-04-26T19:49:22.053791Z"
    }
   },
   "outputs": [],
   "source": [
    "for quality in qualities:\n",
    "    temp = margin_df.loc[(margin_df.margin == 'std') & (margin_df.quality == quality)]\n",
    "    print(quality)\n",
    "    print(f\"Median: {np.median(temp.value)}\")\n",
    "    print(f\"IQR: {stats.iqr(temp.value)}\")\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c43cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.055404Z",
     "start_time": "2022-04-26T19:49:22.055384Z"
    }
   },
   "outputs": [],
   "source": [
    "def sig_test_grid(df, quality, ax):\n",
    "    \n",
    "    metrics = df.metric.drop_duplicates()\n",
    "    data = np.ones((len(metrics), len(non_en)))\n",
    "    highlights = []\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        for j, language in enumerate(non_en):\n",
    "          \n",
    "            value = df.loc[\n",
    "                (df.metric == metric)\n",
    "                & (df.language == language)\n",
    "                & (df.quality == quality),\n",
    "                \"pvalue\",\n",
    "            ].item()\n",
    "            reject_by = df.loc[\n",
    "                (df.metric == metric)\n",
    "                & (df.language == language)\n",
    "                & (df.quality == quality),\n",
    "                \"reject_by\",\n",
    "            ].item()\n",
    "            data[i, j] = value\n",
    "           \n",
    "\n",
    "            if reject_by:\n",
    "                highlights.append((i, j))\n",
    "\n",
    "  \n",
    "    colors = [\"#2061A9\", \"#5C9FCD\", \"#C7DBF0\", \"#FFFFFF\"]\n",
    "    boundaries = [0, 0.05, 1.0]\n",
    "    norm = matplotlib.colors.BoundaryNorm(boundaries=boundaries, ncolors=256)\n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "    sns.heatmap(\n",
    "        data,\n",
    "        ax=ax,\n",
    "        cbar=False,\n",
    "        xticklabels=list(map(str.upper, non_en)),\n",
    "        yticklabels=[renamer.get(x) for x in metrics],\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"lightgray\",\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        cbar_ax=None,\n",
    "        label=quality\n",
    "    )\n",
    "\n",
    "    ax.set_title(quality.title(), size=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "\n",
    "    for i, j in highlights:\n",
    "        ax.add_patch(Rectangle((j, i), 1, 1, fill=True, alpha =1, edgecolor=\"red\", lw=3))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a498e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.057512Z",
     "start_time": "2022-04-26T19:49:22.057475Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, sharex=True, sharey=True, figsize=(8, 8))\n",
    "for i, quality in enumerate(tost_std.quality.drop_duplicates()):\n",
    "    a = i % 2\n",
    "    b = 0 if i < 2 else 1\n",
    "    \n",
    "    sig_test_grid(tost_std, quality, axes[a,b])\n",
    "   \n",
    "    \n",
    "plt.savefig('tost_std_box.pdf', bbox_inches='tight', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999012c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.059075Z",
     "start_time": "2022-04-26T19:49:22.059050Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, sharex=True, sharey=True, figsize=(8,8))\n",
    "for i, quality in enumerate(tost_std.quality.drop_duplicates()):\n",
    "    a = i % 2\n",
    "    b = 0 if i < 2 else 1\n",
    "    \n",
    "    sig_test_grid(tost_constant, quality, axes[a,b])\n",
    "\n",
    "plt.savefig('tost_constant_box.pdf', bbox_inches='tight', format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bc901",
   "metadata": {},
   "source": [
    "## Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6245f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.061406Z",
     "start_time": "2022-04-26T19:49:22.061389Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "margin_df.loc[(margin_df.margin == 'std'), ['quality', 'value']].boxplot(\n",
    "    by='quality',\n",
    "    backend='matplotlib',\n",
    "    figsize=(7,4.5),\n",
    "    boxprops= dict(linewidth=2.2, color='black'), \n",
    "    whiskerprops=dict(linestyle='-',linewidth=2.2, color='black'),\n",
    "    capprops=dict(linestyle='-',linewidth=2.2, color='black'),\n",
    "    medianprops=dict(linestyle='-',linewidth=2.2, color='gray')\n",
    "    \n",
    ")\n",
    "plt.title('Distribution of Margins by Quality', size=17)\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"Margin of Equivalence\", size=17)\n",
    "plt.suptitle('')\n",
    "plt.xticks(size=17)\n",
    "plt.yticks(size=17)\n",
    "plt.savefig(\"boxplot.pdf\", bbox_inches=\"tight\", format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed858e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.062868Z",
     "start_time": "2022-04-26T19:49:22.062847Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.concat(trace).pivot(index=\"margin\", columns=\"quality\")[\"pct\"].plot(figsize=(7, 4.5))\n",
    "plt.xlabel(\"Margin of Equivalence\", size=17)\n",
    "plt.ylabel(\"% of P-Values Under 0.05\", size=17)\n",
    "plt.title(\"TOST Sensitivity to Margin of Equivalence\", size=17)\n",
    "plt.xticks(size=17)\n",
    "plt.yticks(size=17)\n",
    "plt.legend(fontsize=17)\n",
    "\n",
    "plt.savefig(\"tost_sensitivity.pdf\", bbox_inches=\"tight\",format='pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b915c43",
   "metadata": {},
   "source": [
    "## Anderson Hauck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c7400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.065125Z",
     "start_time": "2022-04-26T19:49:22.065094Z"
    }
   },
   "outputs": [],
   "source": [
    "# exp = 1\n",
    "# en = 2\n",
    "# other language = 3\n",
    "# r12 = exp - en correlation\n",
    "# r13 = exp - other correlation\n",
    "# r23 = en - other correlation\n",
    "\n",
    "def anderson_hauck(r12, r13, r23, N, delta=0.1):\n",
    "    \"\"\"\n",
    "    See https://yorkspace.library.yorku.ca/xmlui/bitstream/handle/10315/34580/Counsell_Cribbie.pdf\n",
    "    Page 297\n",
    "    \"\"\"\n",
    "    R = (1 - r12**2 - r13**2 - r23**2) + (2 * r12 * r13 * r23)\n",
    "    stat1 = (\n",
    "        (abs(r12-r13) - delta) * \n",
    "        np.sqrt(\n",
    "            ((N-1)*(1+r23)) / \n",
    "            (2*((N-1)/(N-3)) * R + 0.25*(r12+r13)**2 * (1 - r23)**3)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    stat2 = (\n",
    "        (-1*abs(r12-r13) - delta) * \n",
    "        np.sqrt(\n",
    "            ((N-1)*(1+r23)) / \n",
    "            (2*((N-1)/(N-3)) * R + 0.25*(r12+r13)**2 * (1 - r23)**3)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    p = norm.pdf(stat1) - norm.pdf(stat2)\n",
    "    \n",
    "    return p\n",
    "\n",
    "\n",
    "def ah_corrected(df, margin_name):\n",
    "    reject, corrected, _, _ = multipletests(\n",
    "        df.pvalue,\n",
    "        alpha=0.05,\n",
    "        method=\"fdr_by\",\n",
    "        is_sorted=False,\n",
    "        returnsorted=False,\n",
    "    )\n",
    "    print(f\"Pre Correction Rejection % {df.pvalue.apply(lambda x: x <= 0.05).mean()*100:.2f}\")\n",
    "    print(f\"BY Correction Rejection % {reject.mean()*100:.2f}\")\n",
    "    df[\"reject_by\"] = reject\n",
    "    df[\"pval_by\"] = corrected\n",
    "    df['metric'] = df.submetric\n",
    "    df['language'] = df.language.apply(str.lower)\n",
    "    \n",
    "    plt.figure(figsize=(5,3))\n",
    "    df.pvalue.hist(alpha=0.3, label='Before Correction', bins=10)\n",
    "    df.pval_by.hist(alpha=0.3, label=' B-Y Corrected',bins=10)\n",
    "    \n",
    "    plt.xticks(size=14)\n",
    "    plt.yticks(size=14)\n",
    "    plt.xlabel(\"p-value\", size=14)\n",
    "    plt.ylabel(\"Count\", size=14)\n",
    "    plt.title(f\"{margin_name} Margin\", size=15)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def run_anderson_hauck(df, margin):\n",
    "    N = 1700\n",
    "    ah_results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        r12 = row['en_exp_corr']\n",
    "        r13 = row['lang_exp_corr']\n",
    "        r23 = row['lang_en_corr']\n",
    "        delta = row[margin]\n",
    "        row['pvalue'] = anderson_hauck(r12, r13, r23, N, delta=delta)\n",
    "\n",
    "        ah_results.append(dict(row))\n",
    "        \n",
    "    return pd.DataFrame(ah_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd5002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.067917Z",
     "start_time": "2022-04-26T19:49:22.067894Z"
    }
   },
   "outputs": [],
   "source": [
    "ah_dict = []\n",
    "for met in auto_measures:\n",
    "    for qual in qualities:\n",
    "        for lang in all_data.language.drop_duplicates().tolist():\n",
    "\n",
    "            expert = all_data.loc[\n",
    "                (all_data.submetric == qual)\n",
    "                & (all_data.metric == \"experts\")\n",
    "                & (all_data.language == \"en\"),\n",
    "                \"value\",\n",
    "            ]\n",
    "            \n",
    "            english = all_data.loc[\n",
    "                (all_data.submetric == met)\n",
    "                & (all_data.language == \"en\"),\n",
    "                \"value\",\n",
    "            ]\n",
    "            \n",
    "            other_met = all_data.loc[(all_data.submetric == met) & (all_data.language == lang), \"value\"]\n",
    "\n",
    "            lang_exp_corr = kendalltau(expert, other_met).correlation\n",
    "            lang_en_corr = kendalltau(english, other_met).correlation\n",
    "\n",
    "            ah_dict.append(\n",
    "                dict(\n",
    "                    submetric=met,\n",
    "                    quality=qual.title(),\n",
    "                    language=lang.upper(),\n",
    "                    lang_exp_corr=lang_exp_corr,\n",
    "                    lang_en_corr=lang_en_corr\n",
    "                )\n",
    "            )\n",
    "\n",
    "ah_df = pd.DataFrame(ah_dict).sort_values([\"quality\", \"submetric\", \"language\"]).reset_index(drop=True)\n",
    "ah_df.loc[ah_df.submetric.isin(negative_corrs), [\"lang_exp_corr\"]] = (\n",
    "    ah_df.loc[ah_df.submetric.isin(negative_corrs), [\"lang_exp_corr\"]] * -1\n",
    ")\n",
    "\n",
    "english_corrs = (\n",
    "    ah_df\n",
    "    .loc[ah_df.language == 'EN']\n",
    "    .drop(['lang_en_corr', 'language'], axis=1)\n",
    ")\n",
    "\n",
    "ah_test = (\n",
    "    ah_df.merge(english_corrs, on=['submetric', 'quality'], suffixes=[\"\", \"_en\"])\n",
    "    .rename(columns={'lang_exp_corr_en':'en_exp_corr'})\n",
    "    .loc[ah_df.language != 'EN']\n",
    ")\n",
    "\n",
    "ah_test['margin_std'] = ah_test.apply(lambda x: margins['std'][x.submetric][x.quality.lower()], axis=1)\n",
    "ah_test['margin_maxdiff'] = ah_test.apply(lambda x: margins['max_margin'][x.submetric][x.quality.lower()], axis=1)\n",
    "ah_test['margin_constant'] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598df9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.069950Z",
     "start_time": "2022-04-26T19:49:22.069917Z"
    }
   },
   "outputs": [],
   "source": [
    "ah_std = run_anderson_hauck(ah_test, 'margin_std')\n",
    "ah_corrected(ah_std, \"Standard Deviation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c3009",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.071665Z",
     "start_time": "2022-04-26T19:49:22.071642Z"
    }
   },
   "outputs": [],
   "source": [
    "ah_maxdiff = run_anderson_hauck(ah_test, 'margin_maxdiff')\n",
    "ah_corrected(ah_maxdiff, \"Max Diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb3516",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.073484Z",
     "start_time": "2022-04-26T19:49:22.073454Z"
    }
   },
   "outputs": [],
   "source": [
    "ah_constant = run_anderson_hauck(ah_test, 'margin_constant')\n",
    "ah_corrected(ah_constant, \"Constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0a5f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-26T19:49:22.075354Z",
     "start_time": "2022-04-26T19:49:22.075333Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2, sharex=True, sharey=True, figsize=(8,8))\n",
    "for i, quality in enumerate(ah_std.quality.drop_duplicates()):\n",
    "    a = i % 2\n",
    "    b = 0 if i < 2 else 1\n",
    "    \n",
    "    sig_test_grid(ah_std, quality, axes[a,b])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709ebaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
