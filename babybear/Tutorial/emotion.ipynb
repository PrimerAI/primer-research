{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413f365d",
   "metadata": {},
   "source": [
    "## Emotion dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ca39c1",
   "metadata": {},
   "source": [
    "This notebook is to generate the results on [emotion dataset](https://huggingface.co/datasets/emotion) taken from hugging face. The model in this work is [bhadresh-savani/bert-base-uncased-emotion](https://huggingface.co/bhadresh-savani/bert-base-uncased-emotion)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b004dd67",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import numpy as np\n",
    "import pickle5 as pkl\n",
    "import tensorflow_hub as hub\n",
    "import util_funcs as uf\n",
    "from nlx_babybear import RFBabyBear\n",
    "from inference_triage import PapabearClassifierEmotion, TriagedClassifier\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a82e781",
   "metadata": {},
   "source": [
    "#### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350f8311",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/emotion/train_emotion.pkl'\n",
    "texts_train, y_train, _ = uf.open_pkl(filename)\n",
    "doc, labels = np.asarray(texts_train), np.asarray(y_train)\n",
    "\n",
    "\n",
    "filename = '../data/emotion/test_emotion.pkl'\n",
    "texts_test, y_test, _ = uf.open_pkl(filename)\n",
    "texts_test, y_test = np.asarray(texts_test), np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cae2194",
   "metadata": {},
   "source": [
    "There are 6 classes in this dataset (0:\"sadness\", 1:'joy', 2:'love', 3:'anger', 4:'fear', 5:'surprise'). The distribution of these classes in the training dataset is shown in the following figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels)\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Class distribution on training dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88411140",
   "metadata": {},
   "source": [
    "#### Input file:\n",
    "\n",
    "`model`: The model used as [papabear model]((https://huggingface.co/bhadresh-savani/bert-base-uncased-emotion))\n",
    "\n",
    "`confidence_th_options`: The values for confidence threshold\n",
    "\n",
    "`metric`: The metric to find the performance. It can be one of the \"accuracy\", \"recall\", \"f1_score\" and \"precision\".\n",
    "\n",
    "`metric_threshold`: The minimum value of performance we are expecting for the final model to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b406c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='bhadresh-savani/bert-base-uncased-emotion'\n",
    "metric = \"accuracy\"\n",
    "metric_threshold = .9\n",
    "confidence_th_options = np.arange(0,1.005,.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5171dc",
   "metadata": {},
   "source": [
    "#### Instantiate babybear and papbear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f61d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_model = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "# language_model = SIF(\"latest-small\")\n",
    "papabear = PapabearClassifierEmotion(model)\n",
    "babybear = RFBabyBear(language_model)\n",
    "\n",
    "inf_traige = TriagedClassifier(\"classification\", babybear, papabear, metric_threshold, \"accuracy\", confidence_th_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98ecc5",
   "metadata": {},
   "source": [
    "#### hyper-parameter tuning\n",
    "\n",
    "Here we will train inference triage to find the confidence threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432814bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_traige.train(doc, labels)\n",
    "\n",
    "print(f\"Confidence threshold is: {inf_traige.confidence_th}\")\n",
    "\n",
    "print(f\"The following plots are the saving vs Threshold for different CV fold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d0065d",
   "metadata": {},
   "source": [
    "#### Training babybear model\n",
    "We train the babybear model on all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9b0ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "babybear = RFBabyBear(language_model)\n",
    "babybear.train(doc, labels, n_class=len(np.unique(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb7e731",
   "metadata": {},
   "source": [
    "#### Applying inference triage on the test dataset\n",
    "All the results are also saved in '../output/emotion.resullts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb971b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_traige.babybear = babybear\n",
    "a = inf_traige.score(texts_dev, y_dev)\n",
    "\n",
    "dump_data = {}\n",
    "dump_data['result'] = a\n",
    "dump_data['confidence_th'] = inf_traige.confidence_th\n",
    "dump_data['indx_conf_th'] = inf_traige.indx_conf_th\n",
    "dump_data['metric'] = inf_traige.metric\n",
    "dump_data['metric_threshold'] = inf_traige.metric_threshold\n",
    "dump_data['performance'] = inf_traige.performance\n",
    "dump_data['saving'] = inf_traige.saving\n",
    "dump_data['tot_time'] = inf_traige.tot_time\n",
    "with open('../output/emotion.resullts', 'wb') as outp:  # Overwrites any existing file.\n",
    "        pkl.dump(dump_data, outp, pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb75867",
   "metadata": {},
   "source": [
    "#### Plot cpu/gpu run time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04488da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(inf_traige['tot_time'], np.asarray(inf_traige['performance'])*100, color='r', label='GPU run time')\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel(str(inf_traige['metric']))\n",
    "\n",
    "y = np.arange(0, 105, .1)\n",
    "x = y * 0 + inf_traige['tot_time'][inf_traige['indx_conf_th']]\n",
    "plt.plot(x, y, '--', label='accuracy at confidence threshold =' + str(str(inf_traige['performance'][inf_traige['indx_conf_th']]*100)) + '%')\n",
    "plt.ylim([min(inf_traige['performance'])*100-5, 105])\n",
    "\n",
    "x = np.arange(-.5, max(inf_traige['tot_time'])+.5, .1)\n",
    "y = x * 0 + inf_traige['performance'][inf_traige['indx_conf_th']]*100\n",
    "plt.plot(x, y, '--', label='Time at confidence_th')\n",
    "plt.xlim([-.1, max(inf_traige['tot_time'])+.5])\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff4fb5",
   "metadata": {},
   "source": [
    "Saving vs confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e684e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(0,1.005,.005),inf_traige['saving'], color='r', label='GPU run time')\n",
    "plt.xlabel('confidence threshol')\n",
    "plt.ylabel('saving')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e10b4b",
   "metadata": {},
   "source": [
    "Performance vs confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128a875",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(0,1.005,.005),inf_traige['performance'], color='r', label='GPU run time')\n",
    "plt.xlabel('confidence threshol')\n",
    "plt.ylabel(str(inf_traige['metric']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6417c7",
   "metadata": {},
   "source": [
    "Gpu run time vs confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(0,1.005,.005),inf_traige['tot_time'], color='r', label='GPU run time')\n",
    "plt.xlabel('confidence threshold')\n",
    "plt.ylabel('time')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
